# BARN v3 - Progressive Goal Curriculum
# ============================================================
#
# Key improvements over v2:
# 1. Progressive goal distance (starts near, gets far)
# 2. Progressive waypoint count (1 → 2 → 3)
# 3. Obstacles ONLY between robot and goals
# 4. Longer 20m course for real navigation
# 5. Lateral randomness in goal placement
#
# Curriculum stages:
#   Episode 0-200:    1 goal at 4-6m (basic navigation)
#   Episode 200-400:  2 goals at 5m, 10m (sequencing)
#   Episode 400-600:  3 goals at 5m, 10m, 15m (full course)
#   Episode 600+:     3 goals with max lateral randomness
# ============================================================

robot:
  type: "jackal"
  wheel_radius: 0.098
  track_width: 0.37558
  wheelbase: 0.262
  robot_mass: 17.0
  skid_steer_correction: 4.2

env:
  num_envs: 1

  # LiDAR navigation
  use_camera: false
  use_lidar: true
  lidar_num_points: 180
  lidar_max_range: 10.0

  # Episode settings
  episode_length_s: 120.0      # Longer for multi-goal navigation
  goal_tolerance: 0.6          # Slightly easier tolerance
  arena_radius: 30.0

  # Motor limits (Jackal specs)
  max_wheel_velocity: 20.0
  max_linear_velocity: 2.0
  max_angular_velocity: 4.0

  # ===========================================
  # PROGRESSIVE GOAL CURRICULUM (NEW!)
  # ===========================================

  # Enable progressive curriculum
  use_progressive_goals: true

  # Stage 1: Episodes 0-200 (1 close goal)
  stage1_episodes: 200
  stage1_num_waypoints: 1
  stage1_goal_distance_min: 4.0
  stage1_goal_distance_max: 6.0
  stage1_lateral_range: 1.0      # Small lateral variation

  # Stage 2: Episodes 200-400 (2 goals)
  stage2_episodes: 400
  stage2_num_waypoints: 2
  stage2_goal_spacing: 5.0       # 5m between goals
  stage2_lateral_range: 1.5

  # Stage 3: Episodes 400-600 (3 goals)
  stage3_episodes: 600
  stage3_num_waypoints: 3
  stage3_goal_spacing: 5.0
  stage3_lateral_range: 2.0

  # Stage 4: Episodes 600+ (3 goals, max randomness)
  stage4_num_waypoints: 3
  stage4_goal_spacing: 5.0
  stage4_lateral_range: 2.5      # Full lateral challenge

  # Fallback for non-progressive mode
  num_waypoints: 3
  waypoint_spacing: 5.0
  waypoint_lateral_range: 2.0

  # ===========================================
  # OBSTACLE COURSE (spawn BETWEEN robot and goals)
  # ===========================================

  obstacle_course_type: "barn"
  obstacle_shape: "mixed"        # Both cubes and cylinders

  # Obstacle curriculum
  obstacle_difficulty: 0.3
  use_curriculum: true
  curriculum_start_difficulty: 0.15
  curriculum_end_difficulty: 0.75
  curriculum_episodes_to_max: 600

  # Obstacle counts
  num_obstacles_min: 8
  num_obstacles_max: 35

  # Cylinder dimensions
  cylinder_radius_min: 0.15
  cylinder_radius_max: 0.35
  cylinder_height_min: 0.5
  cylinder_height_max: 1.0

  # Cube dimensions
  obstacle_size_min: [0.25, 0.25, 0.4]
  obstacle_size_max: [0.5, 0.5, 0.8]

  # CRITICAL: Course dimensions (longer course!)
  course_width: 6.0              # 6m width
  course_length: 20.0            # 20m length for multi-goal

  # Obstacles spawn ONLY between robot and furthest goal
  obstacle_spawn_x_min: 1.5      # Start 1.5m from robot
  obstacle_spawn_x_max: 18.0     # Dynamic - will be set to furthest goal
  spawn_obstacles_before_goals: true  # NEW: Only spawn before goals

  # Passage width
  min_passage_width: 0.65        # Tight but passable
  max_passage_width: 1.5

  # Safety clearances
  obstacle_min_spawn_distance: 1.2
  obstacle_waypoint_clearance: 0.8
  randomize_obstacles_on_reset: true
  randomize_obstacle_colors: true

  # ===========================================
  # REWARD CONFIGURATION
  # ===========================================

  # Progress is critical
  reward_progress_scale: 30.0
  reward_away_penalty_scale: 12.0

  # Conditional bonuses
  reward_heading_scale: 0.4
  reward_velocity_scale: 0.2
  reward_smooth_scale: 0.08
  progress_gate: 0.008
  heading_gate: 0.65

  # Forward preference
  reward_reverse_penalty: -0.4

  # Goal rewards (scaled for multi-waypoint)
  reward_waypoint_bonus: 250.0       # Per waypoint
  reward_all_waypoints_bonus: 400.0  # Completion bonus
  reward_collision_penalty: -200.0

  # Obstacle avoidance
  reward_obstacle_danger_zone: 1.0
  reward_obstacle_penalty_max: 6.0

  # Anti-stuck
  reward_stuck_penalty: -2.5
  stuck_threshold_steps: 25
  stuck_movement_threshold: 0.04

ppo:
  policy: "MultiInputPolicy"
  learning_rate: 0.00018
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.995                   # Long horizon for multi-goal
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.015                # Exploration for varied goals
  vf_coef: 0.5
  max_grad_norm: 0.5

training:
  total_timesteps: 1200000       # Longer training for curriculum
  checkpoint_freq: 100000
  log_interval: 10

paths:
  save_dir: "models/ppo_barn_v3"
  log_dir: "logs/ppo_barn_v3"
  tensorboard_dir: "logs/tensorboard"

hardware:
  device: "cuda"
  seed: 42
